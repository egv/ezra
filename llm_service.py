import os
import logging
from typing import List
from openai import AsyncOpenAI

logger = logging.getLogger(__name__)


class LLMService:
    def __init__(self):
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY environment variable is required")
        
        self.client = AsyncOpenAI(api_key=api_key)
        self.model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

    async def generate_digest(self, messages: List[str]) -> str:
        if not messages:
            return "ðŸ“° *Daily Digest - No new messages*\n\nNo new messages were found in monitored channels today."
        
        try:
            combined_messages = "\n\n---\n\n".join(messages)
            
            system_prompt = """Create a telegram message. NEVER use code blocks. NEVER use # headers.

Example output:
*AI News* ðŸ¤–
â€¢ DeepSeek released new model
â€¢ OpenAI updates API

*Tech Updates* ðŸ’»
â€¢ New JavaScript framework
â€¢ Database improvements

Maximum 2000 characters. Use only *bold* and bullets."""
            
            user_prompt = f"""Summarize these messages in telegram format. NO CODE BLOCKS!

{combined_messages[:3000]}

Output like the example - simple bullets and *bold* only."""

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=800,
                temperature=0.3
            )
            
            digest_content = response.choices[0].message.content.strip()
            
            # FORCE removal of any code blocks or # headers the LLM might still generate
            import re
            digest_content = re.sub(r'```[\s\S]*?```', '', digest_content)  # Remove code blocks
            digest_content = re.sub(r'^#+\s*(.*)$', r'*\1*', digest_content, flags=re.MULTILINE)  # Convert headers to bold
            digest_content = digest_content.strip()
            
            header = f"ðŸ“° *Daily Digest - {self._get_current_date()}*\n\n"
            footer = f"\n\n---\n_Generated by Ezra Bot â€¢ {len(messages)} messages processed_"
            
            full_digest = header + digest_content + footer
            
            # Telegram message limit is 4096 characters
            if len(full_digest) > 4000:  # Leave some margin
                # Truncate and add truncation notice
                available_space = 4000 - len(header) - len(footer) - 50  # 50 for truncation notice
                truncated_content = digest_content[:available_space] + "...\n\n*[Truncated due to length]*"
                full_digest = header + truncated_content + footer
            
            return full_digest
            
        except Exception as e:
            logger.error(f"Error generating digest: {e}")
            return f"ðŸ“° *Daily Digest - Error*\n\nSorry, I encountered an error while generating today's digest. Please try again later.\n\nError: {str(e)}"

    async def generate_digest_with_sources(self, messages_data: List[tuple]) -> str:
        """Generate digest with inline source links for the most important messages"""
        if not messages_data:
            return "ðŸ“° *Daily Digest - No new messages*\n\nNo new messages were found in monitored channels today."
        
        try:
            # Step 1: Select the 10 most important messages
            selected_messages = await self._select_most_important_messages(messages_data, limit=10)
            
            # Step 2: Generate digest items with source links for selected messages
            digest_items = []
            
            for msg_data in selected_messages:
                # msg_data format: (message_id, content, message_date, message_link, importance_score)
                content = msg_data[1]
                message_link = msg_data[3]
                
                # Generate a brief summary for this individual message
                system_prompt = """Create ONE bullet point summary for this message. NEVER use code blocks or # headers.
Just return a single bullet point like: â€¢ Brief summary of the main topic"""
                
                user_prompt = f"""Summarize this message in ONE bullet point:\n\n{content[:1000]}"""
                
                response = await self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    max_tokens=100,
                    temperature=0.3
                )
                
                summary = response.choices[0].message.content.strip()
                
                # Clean up the summary
                import re
                summary = re.sub(r'^â€¢\s*', '', summary)  # Remove bullet if LLM added it
                summary = summary.strip()
                
                # Add source link to the summary
                if message_link:
                    digest_items.append(f"â€¢ {summary} ([source]({message_link}))")
                else:
                    digest_items.append(f"â€¢ {summary}")
            
            # Combine all items
            digest_content = "\n".join(digest_items)
            
            header = f"ðŸ“° *Daily Digest - {self._get_current_date()}*\n\n"
            total_messages = len(messages_data)
            selected_count = len(selected_messages)
            footer = f"\n\n---\n_Generated by Ezra Bot â€¢ {selected_count} most important from {total_messages} messages_"
            
            full_digest = header + digest_content + footer
            
            # Telegram message limit is 4096 characters
            if len(full_digest) > 4000:  # Leave some margin
                # Truncate and add truncation notice
                available_space = 4000 - len(header) - len(footer) - 50  # 50 for truncation notice
                truncated_content = digest_content[:available_space] + "...\n\n*[Truncated due to length]*"
                full_digest = header + truncated_content + footer
            
            return full_digest
            
        except Exception as e:
            logger.error(f"Error generating digest with sources: {e}")
            return f"ðŸ“° *Daily Digest - Error*\n\nSorry, I encountered an error while generating today's digest. Please try again later.\n\nError: {str(e)}"

    async def _select_most_important_messages(self, messages_data: List[tuple], limit: int = 10) -> List[tuple]:
        """Select the most important messages using AI analysis"""
        if len(messages_data) <= limit:
            return messages_data
        
        try:
            # Create a condensed list of messages for analysis
            message_summaries = []
            for i, msg_data in enumerate(messages_data):
                content = msg_data[1][:300]  # First 300 chars
                message_summaries.append(f"{i}: {content}")
            
            # Combine all message summaries
            all_messages = "\n\n".join(message_summaries)
            
            system_prompt = f"""You are an AI news curator. Your task is to select the {limit} most important and newsworthy messages from a list of AI/tech messages.

Consider these criteria for importance:
- Breaking news or major announcements
- Significant product releases or updates
- Important research breakthroughs
- Industry-changing events
- High impact developments
- Novel or innovative content

Return ONLY the numbers (0, 1, 2, etc.) of the {limit} most important messages, separated by commas.
Example: 2, 5, 8, 12, 15, 18, 22, 25, 28, 31"""

            user_prompt = f"""Select the {limit} most important messages from this list:

{all_messages[:4000]}

Return only the message numbers separated by commas."""

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=200,
                temperature=0.1  # Low temperature for consistent selection
            )
            
            # Parse the response to get selected message indices
            selection_text = response.choices[0].message.content.strip()
            
            # Extract numbers from the response
            import re
            numbers = re.findall(r'\b\d+\b', selection_text)
            selected_indices = [int(num) for num in numbers if int(num) < len(messages_data)]
            
            # Ensure we don't exceed the limit and have valid indices
            selected_indices = selected_indices[:limit]
            
            # If we couldn't parse properly, fall back to recent messages
            if not selected_indices:
                logger.warning("Failed to parse AI selection, using most recent messages")
                selected_indices = list(range(min(limit, len(messages_data))))
            
            # Return the selected messages
            selected_messages = [messages_data[i] for i in selected_indices]
            
            logger.info(f"Selected {len(selected_messages)} most important messages from {len(messages_data)} total")
            return selected_messages
            
        except Exception as e:
            logger.error(f"Error selecting important messages: {e}, falling back to recent messages")
            # Fallback: return the most recent messages
            return messages_data[:limit]

    def _get_current_date(self) -> str:
        from datetime import datetime
        return datetime.now().strftime("%B %d, %Y")