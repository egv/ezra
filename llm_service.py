import os
import logging
from typing import List
from openai import AsyncOpenAI

logger = logging.getLogger(__name__)


class LLMService:
    def __init__(self):
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY environment variable is required")
        
        self.client = AsyncOpenAI(api_key=api_key)
        self.model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

    async def generate_digest(self, messages: List[str]) -> str:
        if not messages:
            return "üì∞ *Daily Digest - No new messages*\n\nNo new messages were found in monitored channels today."
        
        try:
            combined_messages = "\n\n---\n\n".join(messages)
            
            system_prompt = """Create a telegram message. NEVER use code blocks. NEVER use # headers.

Example output:
*AI News* ü§ñ
‚Ä¢ DeepSeek released new model
‚Ä¢ OpenAI updates API

*Tech Updates* üíª
‚Ä¢ New JavaScript framework
‚Ä¢ Database improvements

Maximum 2000 characters. Use only *bold* and bullets."""
            
            user_prompt = f"""Summarize these messages in telegram format. NO CODE BLOCKS!

{combined_messages[:3000]}

Output like the example - simple bullets and *bold* only."""

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=800,
                temperature=0.3
            )
            
            digest_content = response.choices[0].message.content.strip()
            
            # FORCE removal of any code blocks or # headers the LLM might still generate
            import re
            digest_content = re.sub(r'```[\s\S]*?```', '', digest_content)  # Remove code blocks
            digest_content = re.sub(r'^#+\s*(.*)$', r'*\1*', digest_content, flags=re.MULTILINE)  # Convert headers to bold
            digest_content = digest_content.strip()
            
            header = f"üì∞ *Daily Digest - {self._get_current_date()}*\n\n"
            footer = f"\n\n---\n_Generated by Ezra Bot ‚Ä¢ {len(messages)} messages processed_"
            
            full_digest = header + digest_content + footer
            
            # Telegram message limit is 4096 characters
            if len(full_digest) > 4000:  # Leave some margin
                # Truncate and add truncation notice
                available_space = 4000 - len(header) - len(footer) - 50  # 50 for truncation notice
                truncated_content = digest_content[:available_space] + "...\n\n*[Truncated due to length]*"
                full_digest = header + truncated_content + footer
            
            return full_digest
            
        except Exception as e:
            logger.error(f"Error generating digest: {e}")
            return f"üì∞ *Daily Digest - Error*\n\nSorry, I encountered an error while generating today's digest. Please try again later.\n\nError: {str(e)}"

    async def generate_digest_with_sources(self, messages_data: List[tuple]) -> str:
        """Generate digest using topic-based approach with deduplication"""
        if not messages_data:
            return "üì∞ *Daily Digest - No new messages*\n\nNo new messages were found in monitored channels today."
        
        try:
            # Step 1: Filter out obvious non-news content
            filtered_messages = self._filter_non_news_content(messages_data)
            
            if not filtered_messages:
                return "üì∞ *Daily Digest - No news content*\n\nNo relevant news content found in today's messages."
            
            # Step 2: Extract topics from all messages
            topics = await self._extract_topics_from_messages(filtered_messages)
            
            # Step 3: Group messages by similar topics
            grouped_topics = await self._group_similar_topics(topics)
            
            # Step 4: Select top 10 topics based on importance and mention count
            selected_topics = await self._select_top_topics(grouped_topics, limit=10)
            
            # Step 5: Generate digest from selected topics
            digest_content = await self._generate_digest_from_topics(selected_topics)
            
            header = f"üì∞ *Daily Digest - {self._get_current_date()}*\n\n"
            total_messages = len(messages_data)
            filtered_count = len(filtered_messages)
            topic_count = len(selected_topics)
            footer = f"\n\n---\n_Generated by Ezra Bot ‚Ä¢ {topic_count} topics from {filtered_count} relevant messages (total: {total_messages})_"
            
            full_digest = header + digest_content + footer
            
            # Telegram message limit is 4096 characters
            if len(full_digest) > 4000:  # Leave some margin
                # Truncate and add truncation notice
                available_space = 4000 - len(header) - len(footer) - 50  # 50 for truncation notice
                truncated_content = digest_content[:available_space] + "...\n\n*[Truncated due to length]*"
                full_digest = header + truncated_content + footer
            
            return full_digest
            
        except Exception as e:
            logger.error(f"Error generating digest with sources: {e}")
            return f"üì∞ *Daily Digest - Error*\n\nSorry, I encountered an error while generating today's digest. Please try again later.\n\nError: {str(e)}"

    async def _select_most_important_messages(self, messages_data: List[tuple], limit: int = 10) -> List[tuple]:
        """Select the most important messages using AI analysis"""
        
        # First, apply basic filtering to exclude obvious non-news content
        filtered_messages = self._apply_content_filters(messages_data)
        
        if len(filtered_messages) <= limit:
            return filtered_messages
        
        try:
            # Create a condensed list of messages for analysis
            message_summaries = []
            for i, msg_data in enumerate(filtered_messages):
                content = msg_data[1][:300]  # First 300 chars
                message_summaries.append(f"{i}: {content}")
            
            # Combine all message summaries
            all_messages = "\n\n".join(message_summaries)
            
            system_prompt = f"""You are an AI news curator. Your task is to select the {limit} most important and newsworthy messages from a list of AI/tech messages.

STRICT EXCLUSION RULES - NEVER select messages that contain:
- Thank you messages or gratitude expressions
- Subscriber count updates ("103 subscribers", "1000 readers", etc.)
- Personal greetings or casual chat
- Channel milestone celebrations
- Generic course advertisements without specific AI news
- Personal stories unrelated to AI/tech developments
- Football, sports, dating, or other off-topic content
- Simple promotional posts without technical substance

ONLY INCLUDE messages about:
- NEW AI models, tools, or technologies being released
- Research papers or breakthrough discoveries
- Company announcements in AI/tech space
- Regulatory or legal developments affecting AI
- Significant business deals or investments in AI
- Technical tutorials with specific new information
- Industry analysis with concrete developments

Be extremely selective. Quality over quantity. Exclude anything that looks like personal channel management.

Return ONLY the numbers (0, 1, 2, etc.) of the {limit} most important messages, separated by commas.
Example: 2, 5, 8, 12, 15, 18, 22, 25, 28, 31"""

            user_prompt = f"""Select the {limit} most important messages from this list:

{all_messages[:4000]}

Return only the message numbers separated by commas."""

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=200,
                temperature=0.1  # Low temperature for consistent selection
            )
            
            # Parse the response to get selected message indices
            selection_text = response.choices[0].message.content.strip()
            
            # Extract numbers from the response
            import re
            numbers = re.findall(r'\b\d+\b', selection_text)
            selected_indices = [int(num) for num in numbers if int(num) < len(filtered_messages)]
            
            # Ensure we don't exceed the limit and have valid indices
            selected_indices = selected_indices[:limit]
            
            # If we couldn't parse properly, fall back to recent messages
            if not selected_indices:
                logger.warning("Failed to parse AI selection, using most recent messages")
                selected_indices = list(range(min(limit, len(filtered_messages))))
            
            # Return the selected messages
            selected_messages = [filtered_messages[i] for i in selected_indices]
            
            logger.info(f"Selected {len(selected_messages)} most important messages from {len(filtered_messages)} filtered (originally {len(messages_data)} total)")
            return selected_messages
            
        except Exception as e:
            logger.error(f"Error selecting important messages: {e}, falling back to recent messages")
            # Fallback: return the most recent filtered messages
            return filtered_messages[:limit]

    def _filter_non_news_content(self, messages_data: List[tuple]) -> List[tuple]:
        """Filter out obvious non-news content with stricter rules"""
        filtered_messages = []
        
        # More precise exclude patterns for non-news content
        exclude_patterns = [
            "–ø–æ–¥–ø–∏—Å—á–∏–∫", "subscriber", "—á–∏—Ç–∞—Ç–µ–ª", "—á–µ–ª–æ–≤–µ–∫–∞", "—É—á–∞—Å—Ç–Ω–∏–∫",
            "–±–ª–∞–≥–æ–¥–∞—Ä", "—Å–ø–∞—Å–∏–±–æ", "thank you", "thanks",
            "–∫–∞–Ω–∞–ª —É–∂–µ —á–∏—Ç–∞–µ—Ç", "–∫–∞–Ω–∞–ª –¥–æ—Å—Ç–∏–≥", "–º–æ–π –∫–∞–Ω–∞–ª",
            "—Ä–æ–∑—ã–≥—Ä—ã—à", "giveaway", "–∫–æ–Ω–∫—É—Ä—Å",
            "—Ä–µ–∫–ª–∞–º", "—Å–∫–∏–¥–∫", "discount"
        ]
        
        for msg_data in messages_data:
            content = msg_data[1].lower()
            
            # Skip very short messages
            if len(content.strip()) < 30:
                continue
                
            # Check for exclude patterns
            has_exclude = any(pattern.lower() in content for pattern in exclude_patterns)
            if has_exclude:
                continue
                
            # Include messages that seem to contain actual content
            filtered_messages.append(msg_data)
        
        logger.info(f"Filtered {len(messages_data)} messages down to {len(filtered_messages)} relevant messages")
        return filtered_messages

    async def _extract_topics_from_messages(self, messages_data: List[tuple]) -> List[dict]:
        """Extract topics from messages for grouping"""
        topics = []
        
        for msg_data in messages_data:
            message_id, content, message_date, message_link = msg_data
            
            try:
                system_prompt = """Extract the main topic/event from this message. Return only a brief topic phrase (2-8 words).

Examples:
- "OpenAI releases GPT-5 model"
- "Google antitrust lawsuit"
- "Nvidia earnings report"
- "New AI research paper"

Return only the topic phrase, nothing else."""
                
                user_prompt = f"""Extract the main topic from this message:\n\n{content[:500]}"""
                
                response = await self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    max_tokens=50,
                    temperature=0.1
                )
                
                topic = response.choices[0].message.content.strip().lower()
                
                topics.append({
                    'topic': topic,
                    'message_id': message_id,
                    'content': content,
                    'message_link': message_link,
                    'date': message_date
                })
                
            except Exception as e:
                logger.error(f"Error extracting topic from message {message_id}: {e}")
                # Fallback: use first few words as topic
                fallback_topic = ' '.join(content.split()[:5]).lower()
                topics.append({
                    'topic': fallback_topic,
                    'message_id': message_id,
                    'content': content,
                    'message_link': message_link,
                    'date': message_date
                })
        
        return topics

    async def _group_similar_topics(self, topics: List[dict]) -> List[dict]:
        """Group similar topics together"""
        if not topics:
            return []
        
        grouped_topics = []
        
        for topic_data in topics:
            current_topic = topic_data['topic']
            merged = False
            
            # Check if this topic is similar to any existing group
            for group in grouped_topics:
                similarity = await self._calculate_topic_similarity(current_topic, group['main_topic'])
                
                if similarity > 0.7:  # High similarity threshold
                    # Add to existing group
                    group['messages'].append(topic_data)
                    group['mention_count'] += 1
                    merged = True
                    break
            
            if not merged:
                # Create new group
                grouped_topics.append({
                    'main_topic': current_topic,
                    'messages': [topic_data],
                    'mention_count': 1
                })
        
        logger.info(f"Grouped {len(topics)} topics into {len(grouped_topics)} unique topics")
        return grouped_topics

    async def _calculate_topic_similarity(self, topic1: str, topic2: str) -> float:
        """Calculate similarity between two topics using simple word overlap"""
        # Simple word-based similarity for now
        words1 = set(topic1.lower().split())
        words2 = set(topic2.lower().split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union) if union else 0.0

    async def _select_top_topics(self, grouped_topics: List[dict], limit: int = 10) -> List[dict]:
        """Select top topics based on importance and mention count"""
        if not grouped_topics:
            return []
        
        try:
            # Create topic summaries for importance analysis
            topic_summaries = []
            for i, group in enumerate(grouped_topics):
                main_topic = group['main_topic']
                mention_count = group['mention_count']
                sample_content = group['messages'][0]['content'][:200]
                
                topic_summaries.append(f"{i}: {main_topic} (mentioned {mention_count} times) - {sample_content}")
            
            all_topics = "\n\n".join(topic_summaries)
            
            system_prompt = f"""You are selecting the {limit} most important tech/AI news topics. Consider both topic importance and mention frequency.

Prioritize topics that are:
- Major AI/tech announcements or releases
- Research breakthroughs
- Industry developments
- Regulatory news
- Topics mentioned multiple times (higher mention count = more important)

Return only the numbers (0, 1, 2, etc.) of the {limit} most important topics, separated by commas.
Example: 2, 5, 8, 12, 15"""

            user_prompt = f"""Select the {limit} most important topics from this list:\n\n{all_topics[:4000]}"""

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=200,
                temperature=0.1
            )
            
            # Parse selected indices
            import re
            selection_text = response.choices[0].message.content.strip()
            numbers = re.findall(r'\b\d+\b', selection_text)
            selected_indices = [int(num) for num in numbers if int(num) < len(grouped_topics)]
            
            if not selected_indices:
                # Fallback: select by mention count
                selected_indices = list(range(min(limit, len(grouped_topics))))
            
            selected_topics = [grouped_topics[i] for i in selected_indices[:limit]]
            
            logger.info(f"Selected {len(selected_topics)} top topics from {len(grouped_topics)} total")
            return selected_topics
            
        except Exception as e:
            logger.error(f"Error selecting top topics: {e}")
            # Fallback: return topics sorted by mention count
            sorted_topics = sorted(grouped_topics, key=lambda x: x['mention_count'], reverse=True)
            return sorted_topics[:limit]

    async def _generate_digest_from_topics(self, selected_topics: List[dict]) -> str:
        """Generate final digest from selected topics"""
        if not selected_topics:
            return "No topics selected for digest."
        
        try:
            digest_items = []
            
            for topic_group in selected_topics:
                main_topic = topic_group['main_topic']
                messages = topic_group['messages']
                mention_count = topic_group['mention_count']
                
                # Get the best message content for this topic (longest or most recent)
                best_message = max(messages, key=lambda x: len(x['content']))
                content = best_message['content']
                
                # Generate summary for this topic
                system_prompt = """Create a brief news summary for this topic. Focus on the key facts and developments.
Return only the summary text, no bullets or formatting."""
                
                user_prompt = f"""Summarize this topic: {main_topic}\n\nContent: {content[:800]}"""
                
                response = await self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    max_tokens=150,
                    temperature=0.3
                )
                
                summary = response.choices[0].message.content.strip()
                
                # Collect all source links for this topic
                source_links = []
                for msg in messages:
                    if msg['message_link']:
                        source_links.append(f"[source]({msg['message_link']})")
                
                # Format the digest item
                if source_links:
                    sources_text = ", ".join(source_links)
                    if mention_count > 1:
                        digest_items.append(f"‚Ä¢ {summary} ({sources_text})")
                    else:
                        digest_items.append(f"‚Ä¢ {summary} ({sources_text})")
                else:
                    digest_items.append(f"‚Ä¢ {summary}")
            
            # Categorize the items
            all_items = "\n".join(digest_items)
            
            system_prompt = """Organize these news items into logical categories with emoji headers. NEVER use code blocks or # headers.

Example:
*AI Research* üìö
‚Ä¢ New breakthrough in machine learning
‚Ä¢ Research paper on neural networks

*Industry News* üè¢
‚Ä¢ Company announces new product
‚Ä¢ Merger and acquisition news

Keep ALL items exactly as written. Just add category headers."""
            
            user_prompt = f"""Organize these items into categories:\n\n{all_items}"""
            
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=1500,
                temperature=0.3
            )
            
            categorized_content = response.choices[0].message.content.strip()
            
            # Clean up any unwanted formatting
            import re
            categorized_content = re.sub(r'```[\s\S]*?```', '', categorized_content)
            categorized_content = re.sub(r'^#+\s*(.*)$', r'*\1*', categorized_content, flags=re.MULTILINE)
            
            return categorized_content.strip()
            
        except Exception as e:
            logger.error(f"Error generating digest from topics: {e}")
            # Fallback: simple list
            fallback_items = []
            for topic_group in selected_topics:
                topic = topic_group['main_topic'].title()
                count = topic_group['mention_count']
                fallback_items.append(f"‚Ä¢ {topic} ({count} mentions)")
            
            return "\n".join(fallback_items)

    def _get_current_date(self) -> str:
        from datetime import datetime
        return datetime.now().strftime("%B %d, %Y")